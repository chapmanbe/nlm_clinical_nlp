{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Clinical Natural Language Processing with pyConTextNLP\n",
    "\n",
    "In this notebook we introduce the basics of pyConTextNLP, a simple Python tool that we have used extensively for processing clinical text, including radiology, psychiatry, etc.\n",
    "\n",
    "pyConTextNLP is built around the concept of **targets** and **modifiers**: the target is the concept we are interested in identifying (like a cough or a pulmonary embolism); a modifier is a concept that changes the target in some sense (e.g. historical, severity, certainty, negation).\n",
    "\n",
    "pyConTextNLP relies on [regular expressions](RegularExpressions.ipynb) to identify concepts (both targets and modifiers) within a sentence and then uses simple lexical rules to assign relationships between the identified targets and modifiers. Internally, pyConTextNLP uses graphs. Targets and modifiers are nodes in the graph and relationships between modifiers and targets are edges in the graph.\n",
    "\n",
    "## Specifying targets, modifiers, and rules\n",
    "\n",
    "pyConTextNLP uses a four-tuple to represent concepts. Within the program we create an instance of an ``itemData`` class. Each ``itemData`` consists of the following four attributres:\n",
    "\n",
    "1. A **literal** (e.g. \"pulmonary embolism\", \"no definite evidence of\"): This is a lingustic representation of the target or modifier we want to identify\n",
    "1. A **category** (e.g. \"CRITICAL_FINDING\", \"PROBABLE_EXISTENCE\"): This is the label we want applied to the literal when we see it in text\n",
    "1. A **regular expression** that defines how to identify the literal concept. If no regular expression is specified, a regular expression will be built directly from the literal by wrapping it with word boundaries (e.g. r\"\"\"\\bpulmonary embolism\\b\"\"\")\n",
    "1. A **rule** that defines how the concept works in the sentence (e.g. a negation term that looks **forward** in the sentence). this only applies to modifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pycontextnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyConTextNLP.pyConTextGraph as pyConText\n",
    "import pyConTextNLP.itemData as itemData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The task: Identify patients with pulmonary embolism from radiology reports\n",
    "## Step 1: how is the concept of pulmonary embolism represented in the reports - fill in the list below with literals you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mytargets = itemData.itemData()\n",
    "mytargets.extend([[\"pulmonary embolism\", \"CRITICAL_FINDING\", \"\", \"\"],\n",
    "                   [\"pneumonia\", \"CRITICAL_FINDING\", \"\", \"\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemData: 2 items [pulmonary embolism, pneumonia, ]\n"
     ]
    }
   ],
   "source": [
    "print(mytargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting radnlp\n",
      "  Downloading radnlp-0.2.0.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyConTextNLP in /opt/conda/lib/python3.5/site-packages/pyConTextNLP-0.6.1.2-py3.5.egg (from radnlp)\n",
      "Requirement already satisfied (use --upgrade to upgrade): networkx in /opt/conda/lib/python3.5/site-packages (from pyConTextNLP->radnlp)\n",
      "Requirement already satisfied (use --upgrade to upgrade): nose2 in /opt/conda/lib/python3.5/site-packages (from pyConTextNLP->radnlp)\n",
      "Requirement already satisfied (use --upgrade to upgrade): textblob in /opt/conda/lib/python3.5/site-packages (from pyConTextNLP->radnlp)\n",
      "Requirement already satisfied (use --upgrade to upgrade): decorator>=3.4.0 in /opt/conda/lib/python3.5/site-packages (from networkx->pyConTextNLP->radnlp)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.1 in /opt/conda/lib/python3.5/site-packages (from nose2->pyConTextNLP->radnlp)\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk>=3.1 in /opt/conda/lib/python3.5/site-packages (from textblob->pyConTextNLP->radnlp)\n",
      "Installing collected packages: radnlp\n",
      "Successfully installed radnlp-0.2.0.8\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install radnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Splitting\n",
    "\n",
    "pyConTextNLP operates on a *sentence* level and so the first step we need to take is to split our document into individual sentences. pyConTextNLP comes with a simple sentence splitter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is Dr. Chapman's first sentence.\", 'This is the 2.0 sentence.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyConTextNLP.helpers as helpers\n",
    "spliter = helpers.sentenceSplitter()\n",
    "spliter.splitSentences(\"This is Dr. Chapman's first sentence. This is the 2.0 sentence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sentence splitting is a common NLP task and so most full-fledged NLP applications provide sentence splitters. We usually rely on the sentence splitter that is part of the [TextBlob](https://textblob.readthedocs.io/en/dev/) package, which in turn relies on the Natural Language Toolkit ([NLTK](http://www.nltk.org/)). So before proceeding we need to download some NLTK resources with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
